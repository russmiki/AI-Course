"""
AI Agent Module for Coffee Recommendations
Handles communication with OpenRouter API (GPT-4o-mini)
Builds prompts and manages conversation context
"""

import os
import requests


def ask_ai(prompt):
    """
    Send a single prompt to AI and get response
    
    Args:
        prompt (str): The prompt to send to AI
        
    Returns:
        str: AI's response text
    """
    # Get API key from environment variable
    OPENROUTER_API_KEY = "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"
    
    # Check if API key is configured
    if not OPENROUTER_API_KEY:
        return "âš ï¸ Ú©Ù„ÛŒØ¯ API ØªÙ†Ø¸ÛŒÙ… Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª. Ù„Ø·ÙØ§Ù‹ Ù…ØªØºÛŒØ± Ù…Ø­ÛŒØ·ÛŒ OPENROUTER_API_KEY Ø±Ø§ ØªÙ†Ø¸ÛŒÙ… Ú©Ù†ÛŒØ¯."
        # "âš ï¸ API key not configured. Please set OPENROUTER_API_KEY environment variable."
    
    # OpenRouter API endpoint
    url = "https://openrouter.ai/api/v1/chat/completions"
    
    # Request headers
    headers = {
        "Authorization": f"Bearer {OPENROUTER_API_KEY}",
        "Content-Type": "application/json"
    }
    
    # Request payload with system prompt and user message
    payload = {
        "model": "gpt-4o-mini",  # Using free tier model
        "messages": [
            {
                "role": "system", 
                "content": """ØªÙˆ ÛŒÚ© Ø¨Ø§Ø±ÛŒØ³ØªØ§ÛŒ Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ Ùˆ Ø¯ÙˆØ³ØªØ§Ù†Ù‡ Ù‡Ø³ØªÛŒ Ú©Ù‡ Ø¨Ù‡ ÙØ§Ø±Ø³ÛŒ ØµØ­Ø¨Øª Ù…ÛŒâ€ŒÚ©Ù†ÛŒ.
                
ÙˆØ¸ÛŒÙÙ‡â€ŒØ§Øª Ø§ÛŒÙ†Ù‡ Ú©Ù‡:
1. Ø¨Ø± Ø§Ø³Ø§Ø³ Ø­Ø§Ù„ Ùˆ Ø§Ø­ÙˆØ§Ù„ Ù…Ø´ØªØ±ÛŒØŒ Ø¨Ù‡ØªØ±ÛŒÙ† Ù‚Ù‡ÙˆÙ‡ Ø±Ùˆ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ø¨Ø¯ÛŒ
2. Ø¯Ù„ÛŒÙ„Ø´ Ø±Ùˆ Ø¨Ù‡ Ø²Ø¨ÙˆÙ† Ø³Ø§Ø¯Ù‡ ØªÙˆØ¶ÛŒØ­ Ø¨Ø¯ÛŒ
3. Ù„Ø­Ù† Ø¯ÙˆØ³ØªØ§Ù†Ù‡ Ùˆ ØµÙ…ÛŒÙ…ÛŒ Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´ÛŒ
4. Ø§Ú¯Ø± Ù†ÛŒØ§Ø² Ø¨ÙˆØ¯ØŒ Ù†Ú©Ø§ØªÛŒ Ø¯Ø±Ø¨Ø§Ø±Ù‡ Ø·Ø±Ø² ØªÙ‡ÛŒÙ‡ ÛŒØ§ Ø²Ù…Ø§Ù† Ù…ØµØ±Ù Ø¨Ú¯ÛŒ

Ù‡Ù…ÛŒØ´Ù‡ Ù¾Ø§Ø³Ø®Øª Ø±Ùˆ Ø¨Ø§ Ø§ÛŒÙ…ÙˆØ¬ÛŒ Ù…Ù†Ø§Ø³Ø¨ Ø´Ø±ÙˆØ¹ Ú©Ù† Ùˆ Ø­Ø¯Ø§Ú©Ø«Ø± 4-5 Ø¬Ù…Ù„Ù‡ Ø¨Ø§Ø´Ù‡."""
                # System prompt: "You are a professional and friendly barista who speaks Persian.
                # Your job: 1) Recommend best coffee based on customer's mood
                # 2) Explain reason simply, 3) Use friendly tone
                # 4) Provide preparation tips if needed
                # Always start with emoji, max 4-5 sentences."
            },
            {"role": "user", "content": prompt}
        ],
        "temperature": 0.8,  # Creativity level
        "max_tokens": 500     # Maximum response length
    }
    
    try:
        # Send POST request to OpenRouter
        response = requests.post(url, headers=headers, json=payload, timeout=30)
        response.raise_for_status()  # Raise exception for HTTP errors
        
        # Extract and return AI response
        return response.json()["choices"][0]["message"]["content"]
        
    except requests.exceptions.RequestException as e:
        # Handle request/network errors
        return f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§Ø±ØªØ¨Ø§Ø· Ø¨Ø§ Ø³Ø±ÙˆÛŒØ³ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ: {str(e)}"
        # "âŒ Error connecting to AI service"
        
    except Exception as e:
        # Handle unexpected errors
        return f"âŒ Ø®Ø·Ø§ÛŒ ØºÛŒØ±Ù…Ù†ØªØ¸Ø±Ù‡: {str(e)}"
        # "âŒ Unexpected error"


def build_prompt(data):
    """
    Build a prompt from user form data
    
    Args:
        data (dict): Form cleaned data containing mood, taste, last_coffee, description
        
    Returns:
        str: Formatted prompt for AI
    """
    # Start with basic information
    prompt = f"""ÛŒÚ© Ù…Ø´ØªØ±ÛŒ Ø§ÙˆÙ…Ø¯Ù‡ Ùˆ Ø§ÛŒÙ† Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø±Ùˆ Ø¯Ø§Ø¯Ù‡:

ğŸ§  Ø­Ø§Ù„ Ùˆ Ø§Ø­ÙˆØ§Ù„: {data['mood']}
ğŸ‘… Ø°Ø§Ø¦Ù‚Ù‡: {data['taste']}
â° Ø¢Ø®Ø±ÛŒÙ† Ù‚Ù‡ÙˆÙ‡: {data['last_coffee']}"""
    # "A customer came with this information:
    # Mood: ..., Taste: ..., Last coffee: ..."
    
    # Add optional description if provided
    if data.get('description'):
        prompt += f"\nğŸ’¬ ØªÙˆØ¶ÛŒØ­Ø§Øª Ø§Ø¶Ø§ÙÛŒ: {data['description']}"
        # "Additional details: ..."
    
    # Add recommendation guidelines
    prompt += """

Ø­Ø§Ù„Ø§ Ø¨Ù‡ØªØ±ÛŒÙ† Ù‚Ù‡ÙˆÙ‡ Ø±Ùˆ Ø¨Ø§ ØªÙˆØ¬Ù‡ Ø¨Ù‡ Ø§ÛŒÙ† Ù…ÙˆØ§Ø±Ø¯ Ø¨Ù‡Ø´ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ø¨Ø¯Ù‡:
- Ø§Ú¯Ù‡ Ø®Ø³ØªÙ‡ Ø§Ø³Øª â†’ Ù‚Ù‡ÙˆÙ‡ Ù‚ÙˆÛŒâ€ŒØªØ±
- Ø§Ú¯Ù‡ Ø§Ø³ØªØ±Ø³ Ø¯Ø§Ø±Ù‡ â†’ Ú©Ø§ÙØ¦ÛŒÙ† Ú©Ù…ØªØ± ÛŒØ§ Ø¯Ú©Ù
- Ø§Ú¯Ù‡ ØµØ¨Ø­Ù‡ â†’ Ø§Ø³Ù¾Ø±Ø³Ùˆ ÛŒØ§ Ú©Ø§Ù¾ÙˆÚ†ÛŒÙ†Ùˆ
- Ø§Ú¯Ù‡ Ø¹ØµØ±Ù‡ â†’ Ù‚Ù‡ÙˆÙ‡ Ù…Ù„Ø§ÛŒÙ…â€ŒØªØ±
- Ø§Ú¯Ù‡ Ø¯ÛŒØ± Ù‚Ù‡ÙˆÙ‡ Ø®ÙˆØ±Ø¯Ù‡ â†’ Ù‚Ù‡ÙˆÙ‡ Ù‚ÙˆÛŒâ€ŒØªØ±

Ù¾Ø§Ø³Ø®Øª Ø¨Ø§ÛŒØ¯ Ø®ÛŒÙ„ÛŒ Ø¯ÙˆØ³ØªØ§Ù†Ù‡ØŒ Ú©ÙˆØªØ§Ù‡ (4-5 Ø¬Ù…Ù„Ù‡) Ùˆ Ø¨Ø§ Ø§ÛŒÙ…ÙˆØ¬ÛŒ Ø¨Ø§Ø´Ù‡! ğŸ˜Š"""
    # "Now recommend the best coffee considering:
    # - If tired â†’ stronger coffee
    # - If stressed â†’ less caffeine or decaf
    # - If morning â†’ espresso or cappuccino
    # - If afternoon â†’ milder coffee
    # - If long time since last coffee â†’ stronger coffee
    # Response should be very friendly, short (4-5 sentences) with emojis! ğŸ˜Š"
    
    return prompt


def ask_ai_with_history(conversation_history):
    """
    Send full conversation history to AI for contextual responses
    Used for chat continuation after initial recommendation
    
    Args:
        conversation_history (list): List of message dicts with 'role' and 'content'
        
    Returns:
        str: AI's contextual response
    """
    # Get API key
    OPENROUTER_API_KEY = "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"
    
    # Check if API key is configured
    if not OPENROUTER_API_KEY:
        return "âš ï¸ Ú©Ù„ÛŒØ¯ API ØªÙ†Ø¸ÛŒÙ… Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª."
        # "âš ï¸ API key not configured."
    
    # OpenRouter API endpoint
    url = "https://openrouter.ai/api/v1/chat/completions"
    
    # Request headers
    headers = {
        "Authorization": f"Bearer {OPENROUTER_API_KEY}",
        "Content-Type": "application/json"
    }
    
    # Request payload with full conversation history
    payload = {
        "model": "gpt-4o-mini",
        "messages": conversation_history,  # Include all previous messages
        "temperature": 0.7,  # Slightly lower for more consistent responses
        "max_tokens": 400
    }
    
    try:
        # Send request with conversation context
        response = requests.post(url, headers=headers, json=payload, timeout=30)
        response.raise_for_status()
        
        # Return AI's response
        return response.json()["choices"][0]["message"]["content"]
        
    except Exception as e:
        # Handle errors
        return f"âŒ Ø®Ø·Ø§: {str(e)}"
        # "âŒ Error"